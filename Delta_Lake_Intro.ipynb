{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea57fa41-508a-4224-84b7-87e34555128a",
   "metadata": {},
   "source": [
    "#### In this project, we will use 3 API's: \n",
    "- Spark Sql API: interact with the dataframe as a Spark Sql Table (register the data location)\n",
    "- Pyspark API: create a Spark Dataframe, write & read to a local disk, modify table, read of updated Delta Lake contents\n",
    "- Delta Lake Python API: modify a table (upsert & merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a2ce85-143b-4bb6-b77e-c22346e0a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_args_str = \"\"\"\n",
    "--packages \"io.delta:delta-core_2.12:1.0.0\"\n",
    "--conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\"\n",
    "--conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\" pyspark-shell\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25bf064-e479-439f-939f-cbee610536b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n--packages \"io.delta:delta-core_2.12:1.0.0\"\\n--conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\"\\n--conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\" pyspark-shell\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_args_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800e978d-cd9d-41fc-8f2b-05c7d7afe3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.get(\"PYSPARK_SUBMIT_ARGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237723fd-bf53-4bd1-8c84-df3052efa6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = pyspark_args_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14aec3b7-5bdc-404b-80a2-49f8fca15823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n--packages \"io.delta:delta-core_2.12:1.0.0\"\\n--conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\"\\n--conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\" pyspark-shell\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get(\"PYSPARK_SUBMIT_ARGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a388591-5bfc-4df8-a1ea-1cbe8722d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[8]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16a95d-0519-4cad-abab-93699ed8d386",
   "metadata": {},
   "source": [
    "####  Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10827e94-64f2-4b16-90c6-4e34b6b7f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kids = [\n",
    "    {'name': 'Alice', 'age': 1},\n",
    "    {'name': 'Berto', 'age': 7},\n",
    "    {'name': 'Chen', 'age': 4},\n",
    "    {'name': 'Dinesh', 'age': 6},\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(kids, schema=\"name STRING, age INT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be62384-dfc1-410a-8715-bba9f929c7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "| Alice|  1|\n",
      "| Berto|  7|\n",
      "|  Chen|  4|\n",
      "|Dinesh|  6|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36223ca3-fd65-44eb-a0ae-27940e6c06fb",
   "metadata": {},
   "source": [
    "#### Write data to a local disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a515b936-66f4-4fc0-9471-ea283ebb12ae",
   "metadata": {},
   "source": [
    "(\n",
    "df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"path\", \"/home/jovyan/data/kids\")\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62dc395-5e2c-4c16-b84d-8c1bcd02178e",
   "metadata": {},
   "source": [
    "#### Reading data from the local disk to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f82708-4208-4930-a434-d68e39466535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "|Dinesh|  6|\n",
      "| Berto|  7|\n",
      "| Alice|  1|\n",
      "|  Chen|  4|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "spark.read\n",
    "    .format(\"delta\")\n",
    "    .option(\"path\", \"/home/jovyan/data/kids\")\n",
    "    .load()\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16f7f7-dc40-4910-ba3b-8a5837346735",
   "metadata": {},
   "source": [
    "#### Creating a data location for the Spark Sql Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18c3eb48-4005-4ef6-82a2-a28b05b01bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE kids\n",
    "  USING delta\n",
    "  LOCATION '/home/jovyan/data/kids'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d49eba60-67e6-49c8-a6c2-23a3c40712a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------------+-----------+--------------------+--------------------+--------------------+----------------+--------+-----------+----------+----------------+----------------+\n",
      "|format|                  id|        name|description|            location|           createdAt|        lastModified|partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|\n",
      "+------+--------------------+------------+-----------+--------------------+--------------------+--------------------+----------------+--------+-----------+----------+----------------+----------------+\n",
      "| delta|29bd423d-d7db-46b...|default.kids|       null|file:/home/jovyan...|2021-06-28 14:29:...|2021-06-28 14:29:...|              []|       5|       2978|        {}|               1|               2|\n",
      "+------+--------------------+------------+-----------+--------------------+--------------------+--------------------+----------------+--------+-----------+----------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE DETAIL kids\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4aa042-cb6a-41cd-ac3b-431c35d52829",
   "metadata": {},
   "source": [
    "#### Read data from the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1ed20-f946-47c1-aaf7-a4700b9c0569",
   "metadata": {},
   "source": [
    "spark.sql(\"SELECT * FROM kids\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24854f86-a3de-4d12-a999-342d47dce342",
   "metadata": {},
   "source": [
    "#### Modifying the table using the Delta Lake Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0eb307e-7bd2-4385-902d-9abe42cb1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = spark.createDataFrame([\n",
    "    {\"name\": \"Berto\", \"age\": 8},\n",
    "    {\"name\": \"Eva\", \"age\": 0}\n",
    "], schema=\"name STRING, age INT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65daf5fa-6507-4b70-b681-f431cad0a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ddaf5-b3cf-4b08-bd3e-eb5318d1d7dd",
   "metadata": {},
   "source": [
    "#### Reference the location of the data and perform the update (upsert / merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "458f5956-0e68-42fe-b057-2af93d131869",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, \"/home/jovyan/data/kids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ba676c2-f2fd-40db-bb05-d7a01a85ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    deltaTable.alias(\"kids\")\n",
    "    .merge(\n",
    "        update.alias(\"update\"),\n",
    "        \"kids.name = update.name\"\n",
    "    )\n",
    "    .whenMatchedUpdate(set={\"age\": col(\"update.age\")})\n",
    "    .whenNotMatchedInsert(values={\"name\": col(\"update.name\"), \"age\": col(\"update.age\")})\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3598f-1ddb-4da2-9132-f8332c0ec9ab",
   "metadata": {},
   "source": [
    "##### use Pyspark to read the contents of the updated Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071df0d1-e799-49c1-a0f0-378be99582a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "|Dinesh|  6|\n",
      "| Berto|  8|\n",
      "| Alice|  1|\n",
      "|  Chen|  4|\n",
      "|   Eva|  0|\n",
      "+------+---+\n",
      "\n",
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "|Dinesh|  6|\n",
      "| Berto|  7|\n",
      "| Alice|  1|\n",
      "|  Chen|  4|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").option(\"path\", \"data/kids\").load().show()\n",
    "df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"data/kids\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9c162-1264-4a43-b00d-79becba3b908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca69aa4-4ca0-4617-9323-7a944990b53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b9db4-96a4-4e8d-b992-c1646aef4bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
